## Arquitetura Medallion

### ğŸ¥‰ Bronze Layer
- Consome dados brutos da API FakeStore
- Armazena dados em formato bruto dentro do container Docker
- MantÃ©m fidelidade total Ã  fonte original

### ğŸ¥ˆ Silver Layer
- Limpeza e padronizaÃ§Ã£o dos dados
- NormalizaÃ§Ã£o de estruturas
- PersistÃªncia em PostgreSQL

### ğŸ¥‡ Gold Layer
ğŸš§ Ainda nÃ£o implementada  

Planejada para conter:
- AgregaÃ§Ãµes analÃ­ticas
- MÃ©tricas de negÃ³cio
- Tabelas otimizadas para BI


## ğŸ›  Tecnologias Utilizadas

- **Python** (Requests, Pandas, SQLAlchemy)
- **PostgreSQL**
- **Apache Airflow**
- **Docker & Docker Compose**
- **Arquitetura Medallion (Bronze/Silver/Gold)**


## ğŸ“‚ Estrutura do Projeto
```
data-engineering-fakestore/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ ingestion/
â”‚ â”œâ”€â”€ loading/
â”‚ â”œâ”€â”€ transformation_silver/
â”‚ â””â”€â”€ transformation_gold/ (planejado)
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ bronze/
â”‚ â”œâ”€â”€ silver/
â”‚ â””â”€â”€ gold/
â”œâ”€â”€ airflow/
â”‚ â”œâ”€â”€ dags/
â”‚ â”œâ”€â”€ docker-compose.yml
```
## ğŸ³ Executando o Projeto

O `docker-compose.yml` estÃ¡ localizado dentro da pasta `airflow/`.

### Subir ambiente:

```bash
cd airflow
docker compose up --build
```

## ğŸ” VariÃ¡veis de Ambiente
Criar arquivo .env na raiz do projeto com:
```
POSTGRES_USER=
POSTGRES_PASSWORD=
POSTGRES_DB=
POSTGRES_HOST=
POSTGRES_PORT=
```

## ğŸš€ Pipeline de Dados
O pipeline realiza:

* ExtraÃ§Ã£o de dados da API FakeStore
* Armazenamento bruto (Bronze)
* TransformaÃ§Ã£o e limpeza (Silver)
* Carga estruturada no PostgreSQL
* OrquestraÃ§Ã£o via Airflow

## ğŸ“Œ Roadmap / Melhorias Futuras

- [ ] Implementar camada Gold
- [ ] Criar agregaÃ§Ãµes analÃ­ticas
- [ ] Adicionar testes automatizados
- [ ] Implementar logging estruturado
- [ ] Deploy em cloud (AWS/GCP)
- [ ] Implementar CI/CD

## ğŸ¯ Objetivo do Projeto

Demonstrar conhecimento em:

- Arquitetura de pipelines de dados
- OrganizaÃ§Ã£o em camadas (Medallion Architecture)
- OrquestraÃ§Ã£o com Airflow
- PersistÃªncia em banco relacional
- Boas prÃ¡ticas de versionamento
- EstruturaÃ§Ã£o de projeto para produÃ§Ã£o



## âš™ï¸ EstratÃ©gia de Carga â€“ ParÃ¢metros do Airflow

O pipeline foi configurado para permitir diferentes estratÃ©gias de extraÃ§Ã£o atravÃ©s de parÃ¢metros na DAG do Airflow.

A funÃ§Ã£o `extract_products()` suporta trÃªs modos de execuÃ§Ã£o:

- **Full Load**
- **Range Load**
- **Incremental Load (padrÃ£o)**

---

### ğŸ¥‰ 1ï¸âƒ£ Full Load (`mode="full"`)

Realiza uma carga completa dos dados disponÃ­veis na API.

- Remove todos os dados existentes no arquivo Bronze
- Reprocessa todos os IDs disponÃ­veis na FakeStore (1â€“20)
- Sobrescreve o arquivo `products.json`

ğŸ“Œ Uso recomendado:
- Primeira carga
- Reprocessamento total
- CorreÃ§Ã£o de inconsistÃªncias

### ğŸ”¢ 2ï¸âƒ£ Range Load (`mode="range"`)

Permite reprocessar um intervalo especÃ­fico de IDs.

ParÃ¢metros necessÃ¡rios:
- `min_id`
- `max_id`

O pipeline irÃ¡:
- Buscar apenas os IDs dentro do intervalo informado
- Atualizar ou substituir esses registros no Bronze

ğŸ“Œ Uso recomendado:
- CorreÃ§Ã£o de registros especÃ­ficos
- Reprocessamento controlado
- Testes

### ğŸ“ˆ 3ï¸âƒ£ Incremental Load (padrÃ£o)

Se nenhum parÃ¢metro for informado, o pipeline executa automaticamente em modo incremental.

Comportamento:

- Verifica os IDs jÃ¡ existentes no arquivo Bronze
- Identifica o prÃ³ximo ID disponÃ­vel
- Busca apenas o novo registro
- MantÃ©m os dados jÃ¡ existentes

ğŸ“Œ Esse Ã© o comportamento padrÃ£o da DAG.

## ğŸ¯ BenefÃ­cios da Abordagem

- Flexibilidade operacional
- Reprocessamento controlado
- Suporte a cargas completas e incrementais
- Maior controle sobre ingestÃ£o de dados
- Simula cenÃ¡rios reais de engenharia de dados